{
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CanYouCatchIt?\n",
    "A web application allowing you to obtain the percentage of chance that your bus/tram/metro is late. ðŸ’»ðŸ¤–ðŸŽ²ðŸšŒ ðŸšŽðŸš‡ðŸ”®\n",
    "\n",
    "_Build with the STIB API (available [here](https://opendata.stib-mivb.be/store/))_\n",
    "\n",
    "# Notes: Making some models ðŸ’»ðŸ¤–ðŸšŒ ðŸšŽðŸš‡\n",
    "We are here to make some machine learning models"
   ]
  },
  {
   "source": [
    "## Load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "\n",
    "def load_delay_data():\n",
    "    \"\"\"\n",
    "    Load the cvs file in a panda dataframe\n",
    "    \"\"\"\n",
    "    return pd.concat([pd.read_csv(f) for f in glob.glob('../data/delay*.csv')], ignore_index = True)\n",
    "\n",
    "# load the csv file\n",
    "delay = load_delay_data()\n",
    "delay.dropna(inplace=True)\n",
    "delay.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get names of indexes for which column line has not a value of 39\n",
    "index_to_remove = delay[delay['line'] != 39].index\n",
    "# Delete these row indexes from dataFrame\n",
    "delay.drop(index_to_remove , inplace=True)\n",
    "\n",
    "nunique = delay.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "delay = delay.drop(cols_to_drop, axis=1)\n",
    "\n",
    "delay = delay.drop(['trip', 'theoretical_time', 'expectedArrivalTime', 'date'], axis=1)\n",
    "\n",
    "# Reset the labels\n",
    "delay.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Stratifie the data with the different line\n",
    "# This make sure that the representation of each stop is the same in the train set then in the overall dataset\n",
    "# This stratification is not necessary is you have enough data\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(delay, delay[\"hour\"]):\n",
    "    strat_train_set = delay.loc[train_index]\n",
    "    strat_test_set = delay.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = strat_train_set.drop(\"delay\", axis=1) # drop labels for training set\n",
    "delay_labels = strat_train_set[\"delay\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there is row with nan\n",
    "\n",
    "Count the number of row with a nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "sample_incomplete_rows = delay[delay.isnull().any(axis=1)].head()\n",
    "len(sample_incomplete_rows.index)"
   ]
  },
  {
   "source": [
    "### Check if there is attribute that are the same for every row"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "def unique_cols(df):\n",
    "    a = df.to_numpy()\n",
    "    return (a[0] == a).all(0)\n",
    "unique_cols(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['stop', 'day', 'hour', 'minute', 'temp', 'humidity', 'visibility',\n",
       "       'wind', 'rain'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "delay.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Drop the unnecesery attribute. theoretical_time and expectedArrivalTime are droped because they are string attribute and they are not linked to the delay value. The date attribute is split into hour minute and seconds so it can be droped. The transport_type, year, month, visibility and rain attribute is droped because, it's the same for every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       stop  day  hour  minute    temp  humidity  visibility  wind  rain\n",
       "39910  5508    0    19      27  281.35      87.0     10000.0   1.0   0.0\n",
       "22073  5529    5     9       1  280.13      81.0     10000.0   4.6   0.0\n",
       "42184  5512    1     7      33  280.11      93.0     10000.0   2.6   0.0\n",
       "40202  5515    0    20      10  281.71      87.0     10000.0   1.5   0.0\n",
       "52515  5519    2    22      58  280.81      81.0     10000.0   4.1   0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n      <th>temp</th>\n      <th>humidity</th>\n      <th>visibility</th>\n      <th>wind</th>\n      <th>rain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39910</th>\n      <td>5508</td>\n      <td>0</td>\n      <td>19</td>\n      <td>27</td>\n      <td>281.35</td>\n      <td>87.0</td>\n      <td>10000.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22073</th>\n      <td>5529</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>280.13</td>\n      <td>81.0</td>\n      <td>10000.0</td>\n      <td>4.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>42184</th>\n      <td>5512</td>\n      <td>1</td>\n      <td>7</td>\n      <td>33</td>\n      <td>280.11</td>\n      <td>93.0</td>\n      <td>10000.0</td>\n      <td>2.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40202</th>\n      <td>5515</td>\n      <td>0</td>\n      <td>20</td>\n      <td>10</td>\n      <td>281.71</td>\n      <td>87.0</td>\n      <td>10000.0</td>\n      <td>1.5</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>52515</th>\n      <td>5519</td>\n      <td>2</td>\n      <td>22</td>\n      <td>58</td>\n      <td>280.81</td>\n      <td>81.0</td>\n      <td>10000.0</td>\n      <td>4.1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "nunique = delay.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "delay = delay.drop(cols_to_drop, axis=1)\n",
    "delay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Text and Categorical Attributes\n",
    "### Extract the non-numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_num = delay.drop(['stop'], axis=1)"
   ]
  },
  {
   "source": [
    "### Categorical Attributes: The stop and attributes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       stop\n",
       "39910  5508\n",
       "22073  5529\n",
       "42184  5512\n",
       "40202  5515\n",
       "52515  5519"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39910</th>\n      <td>5508</td>\n    </tr>\n    <tr>\n      <th>22073</th>\n      <td>5529</td>\n    </tr>\n    <tr>\n      <th>42184</th>\n      <td>5512</td>\n    </tr>\n    <tr>\n      <th>40202</th>\n      <td>5515</td>\n    </tr>\n    <tr>\n      <th>52515</th>\n      <td>5519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "delay_cat = delay[['stop']]\n",
    "delay_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 7.],\n",
       "       [16.],\n",
       "       [10.],\n",
       "       [11.],\n",
       "       [15.],\n",
       "       [ 1.],\n",
       "       [12.],\n",
       "       [ 8.],\n",
       "       [10.],\n",
       "       [14.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "delay_cat_encoded = ordinal_encoder.fit_transform(delay_cat)\n",
    "delay_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       stop day hour minute    temp humidity visibility wind rain  \\\n",
       "39910  5508   0   19     27  281.35       87      10000    1    0   \n",
       "22073  5529   5    9      1  280.13       81      10000  4.6    0   \n",
       "42184  5512   1    7     33  280.11       93      10000  2.6    0   \n",
       "40202  5515   0   20     10  281.71       87      10000  1.5    0   \n",
       "52515  5519   2   22     58  280.81       81      10000  4.1    0   \n",
       "\n",
       "      hour_and_minute  \n",
       "39910           70020  \n",
       "22073           32460  \n",
       "42184           27180  \n",
       "40202           72600  \n",
       "52515           82680  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n      <th>temp</th>\n      <th>humidity</th>\n      <th>visibility</th>\n      <th>wind</th>\n      <th>rain</th>\n      <th>hour_and_minute</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39910</th>\n      <td>5508</td>\n      <td>0</td>\n      <td>19</td>\n      <td>27</td>\n      <td>281.35</td>\n      <td>87</td>\n      <td>10000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>70020</td>\n    </tr>\n    <tr>\n      <th>22073</th>\n      <td>5529</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>280.13</td>\n      <td>81</td>\n      <td>10000</td>\n      <td>4.6</td>\n      <td>0</td>\n      <td>32460</td>\n    </tr>\n    <tr>\n      <th>42184</th>\n      <td>5512</td>\n      <td>1</td>\n      <td>7</td>\n      <td>33</td>\n      <td>280.11</td>\n      <td>93</td>\n      <td>10000</td>\n      <td>2.6</td>\n      <td>0</td>\n      <td>27180</td>\n    </tr>\n    <tr>\n      <th>40202</th>\n      <td>5515</td>\n      <td>0</td>\n      <td>20</td>\n      <td>10</td>\n      <td>281.71</td>\n      <td>87</td>\n      <td>10000</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>72600</td>\n    </tr>\n    <tr>\n      <th>52515</th>\n      <td>5519</td>\n      <td>2</td>\n      <td>22</td>\n      <td>58</td>\n      <td>280.81</td>\n      <td>81</td>\n      <td>10000</td>\n      <td>4.1</td>\n      <td>0</td>\n      <td>82680</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "def add_extra_features(X, add_combined_time=True):\n",
    "    hour_ix, minute_ix = [list(delay.columns).index(col) for col in (\"hour\", \"minute\")]\n",
    "    if add_combined_time:\n",
    "        hour_and_minute = X[:, hour_ix]*3600 + X[:, minute_ix]*60\n",
    "        return np.c_[X, hour_and_minute]\n",
    "    else:\n",
    "        return np.c_[X]\n",
    "\n",
    "attr_adder = FunctionTransformer(add_extra_features, validate=False,\n",
    "                                 kw_args={\"add_combined_time\": True})\n",
    "delay_extra_attribs = attr_adder.fit_transform(delay.values)\n",
    "\n",
    "delay_extra_attribs = pd.DataFrame(\n",
    "    delay_extra_attribs,\n",
    "    columns=list(delay.columns) + [\"hour_and_minute\"],\n",
    "    index=delay.index)\n",
    "delay_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.80705681,  1.00147761, -0.15699833, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.99854211, -0.94176764, -1.66707087, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.24593703, -1.33041669,  0.19147994, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.68481724,  1.00147761, -1.02819403, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.5596619 , -0.94176764,  0.4237988 , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.12369746,  1.19580214,  0.4237988 , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_attribs = list(delay_num)\n",
    "cat_attribs = [\"stop\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', FunctionTransformer(add_extra_features,\n",
    "                                            validate=False,\n",
    "                                            kw_args={\"add_combined_time\": True})), # change the add_combined_time attribute to test without the hour_and_minute\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "delay_prepared = full_pipeline.fit_transform(delay)\n",
    "delay_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and train a model\n",
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       stop  day  hour  minute    temp  humidity  visibility  wind  rain\n",
       "39910  5508    0    19      27  281.35      87.0     10000.0   1.0   0.0\n",
       "22073  5529    5     9       1  280.13      81.0     10000.0   4.6   0.0\n",
       "42184  5512    1     7      33  280.11      93.0     10000.0   2.6   0.0\n",
       "40202  5515    0    20      10  281.71      87.0     10000.0   1.5   0.0\n",
       "52515  5519    2    22      58  280.81      81.0     10000.0   4.1   0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n      <th>temp</th>\n      <th>humidity</th>\n      <th>visibility</th>\n      <th>wind</th>\n      <th>rain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39910</th>\n      <td>5508</td>\n      <td>0</td>\n      <td>19</td>\n      <td>27</td>\n      <td>281.35</td>\n      <td>87.0</td>\n      <td>10000.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>22073</th>\n      <td>5529</td>\n      <td>5</td>\n      <td>9</td>\n      <td>1</td>\n      <td>280.13</td>\n      <td>81.0</td>\n      <td>10000.0</td>\n      <td>4.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>42184</th>\n      <td>5512</td>\n      <td>1</td>\n      <td>7</td>\n      <td>33</td>\n      <td>280.11</td>\n      <td>93.0</td>\n      <td>10000.0</td>\n      <td>2.6</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40202</th>\n      <td>5515</td>\n      <td>0</td>\n      <td>20</td>\n      <td>10</td>\n      <td>281.71</td>\n      <td>87.0</td>\n      <td>10000.0</td>\n      <td>1.5</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>52515</th>\n      <td>5519</td>\n      <td>2</td>\n      <td>22</td>\n      <td>58</td>\n      <td>280.81</td>\n      <td>81.0</td>\n      <td>10000.0</td>\n      <td>4.1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "delay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(delay_prepared, delay_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions: \t [-0.1796875  -1.0078125  -1.51367188 -0.47851562 -0.53125   ]\nLabels: \t [-11.0, -21.0, -2.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = delay.iloc[:5]\n",
    "some_labels = delay_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions: \\t\", lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels: \\t\", list(some_labels))"
   ]
  },
  {
   "source": [
    "The model is working although the predictions are not accurate at all\n",
    "\n",
    "Compute the error"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.80474925420959"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "delay_predictions = lin_reg.predict(delay_prepared)\n",
    "lin_mse = mean_squared_error(delay_labels, delay_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "source": [
    "Okay, this is better than nothing but clearly not a great score: the delay's value range from 10min to -20min, so a typical prediction error of 5min is not very satisfying."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.4729964513845393"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(delay_labels, delay_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "source": [
    "### Decision Tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(delay_prepared, delay_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "delay_predictions = tree_reg.predict(delay_prepared)\n",
    "tree_mse = mean_squared_error(delay_labels, delay_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "source": [
    "No error? The model has overfit ðŸ˜–\n",
    "\n",
    "To evaluate the Decision Tree model we can split the training set into smaller training set and validation set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "The following code performs 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \\t\\t\", scores)\n",
    "    print(\"Mean: \\t\\t\\t\", scores.mean())\n",
    "    print(\"Standard deviation: \\t\", scores.std())"
   ]
  },
  {
   "source": [
    "#### Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: \t\t [4.7934094  5.00696886 4.73008548 4.87701602 4.68490766 4.83864952\n 4.69290144 4.90588867 4.80429485 4.726187  ]\nMean: \t\t\t 4.806030891150337\nStandard deviation: \t 0.09809418145911174\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, delay_prepared, delay_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "source": [
    "#### Decision Tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: \t\t [5.72198631 5.95193576 5.76778964 5.78252051 5.5234445  5.71216682\n 5.67960154 5.8767724  5.77004077 5.97526949]\nMean: \t\t\t 5.7761527754324495\nStandard deviation: \t 0.1268980293823553\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree_reg, delay_prepared, delay_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "source": [
    "We can see taht the Decision Tree model is overfitting so strongly that the Linear Regression model performs even better."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=42)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(delay_prepared, delay_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.899398305468675"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "delay_predictions = forest_reg.predict(delay_prepared)\n",
    "forest_mse = mean_squared_error(delay_labels, delay_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: \t\t [4.49773023 4.73560118 4.44931363 4.65384398 4.37805599 4.62957447\n 4.49554659 4.69674871 4.59968735 4.59054964]\nMean: \t\t\t 4.572665177045496\nStandard deviation: \t 0.10838562780976058\n"
     ]
    }
   ],
   "source": [
    "forest_scores = cross_val_score(forest_reg, delay_prepared, delay_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "source": [
    "With the Random Forest we have a mutch better results. But we see a significant difference between the score on the training set than on the validation set. That means that the model is still overfitting the training set.\n",
    "\n",
    "#### Support Vector Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(delay_prepared, delay_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.839773395843052"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "delay_predictions = svm_reg.predict(delay_prepared)\n",
    "svm_mse = mean_squared_error(delay_labels, delay_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_scores = cross_val_score(svm_reg, delay_prepared, delay_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svr_rmse_scores = np.sqrt(-svr_scores)\n",
    "display_scores(svr_rmse_scores)"
   ]
  },
  {
   "source": [
    "We can see that the best model is the Random Forest ðŸŒ²"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune the models\n",
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3Ã—4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2Ã—3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(delay_prepared, delay_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "source": [
    "We should evaluate higher values of n_estimators as well, since 30 is the maximum value that was evaluated. The score may continue to improve."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    # try 12 (3Ã—4) combinations of hyperparameters\n",
    "    {'n_estimators': [60, 70, 80], 'max_features': [6, 8, 9, 10]},\n",
    "    # then try 9 (3Ã—3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [70, 80, 90], 'max_features': [1, 2, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+9)*5=105 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(delay_prepared, delay_labels)\n",
    "print(grid_search.best_params_, \"\\n\")\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(delay_prepared, delay_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "source": [
    "### Analyze the Best Models and Their Errors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# only in a Jupyter notebook column=\"delay\"\n",
    "\n",
    "extra_attribs = [\"hour_and_minute\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "print(sorted(zip(attributes, feature_importances), key=lambda feature: feature[1], reverse=True))\n",
    "plt.barh(*zip(*sorted(zip(attributes, feature_importances), key=lambda feature: feature[1], reverse=True)), align='center', alpha=0.5)"
   ]
  },
  {
   "source": [
    "We can see that the most important value is the newly added \"hour_and_minute\" attribute.\n",
    "### Analyze the Best Models and Their Errors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"delay\", axis=1)\n",
    "y_test = strat_test_set[\"delay\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "mean = squared_errors.mean()\n",
    "m = len(squared_errors)\n",
    "\n",
    "np.sqrt(stats.t.interval(confidence, m - 1,\n",
    "                         loc=np.mean(squared_errors),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", RandomForestRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor.fit(delay, delay_labels)\n",
    "# print(some_labels.array)\n",
    "# print(full_pipeline_with_predictor.predict(some_data))\n",
    "\n",
    "test_set = strat_test_set.drop(\"delay\", axis=1) # drop labels for test set\n",
    "test_set_labels = strat_test_set[\"delay\"].copy()\n",
    "print(test_set_labels[:5].array)\n",
    "print(full_pipeline_with_predictor.predict(test_set[:5]))"
   ]
  },
  {
   "source": [
    "### Save the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "my_model = full_pipeline_with_predictor\n",
    "joblib.dump(my_model, \"../models/my_model.pkl\") # save\n",
    "\n",
    "# my_model_loaded = joblib.load(\"my_model.pkl\") # load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}